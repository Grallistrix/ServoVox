###

#base_prompt = ""
#query= base_prompt+result.text

#get ollama response
#response = requests.post(
#    "http://localhost:11434/v1/completions",
#    json={"model": "llama3:latest", "prompt": query}
#)
#print("Query: "+query+"\n")
#print("Response:\n"+response.json()["choices"][0]["text"])
